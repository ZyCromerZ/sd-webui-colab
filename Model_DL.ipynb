{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZyCromerZ/sd-webui-colab/blob/main/Copy_of_Model_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsObH3kCeHDi"
      },
      "source": [
        "## **Model DL (NoCrypt#6416)**\n",
        "\n",
        "\n",
        "Can be used to download models and distribute them to Hugging Face and Google Drive (aka. Mirror)<br>\n",
        "Can also be used to covert ckpt to safetensors<br>\n",
        "<fieldset>\n",
        "    <legend>\n",
        "    <h2><b>Why?</b></h2>\n",
        "    </legend>\n",
        "\n",
        "<i>Because not everyone have access to a fast internet (incl. myself), therefore this colab can help them download all models they want and distribute them to Hugging Face and Google Drive without needing them to download to their computer, **which will take them ages to do so**.</i>\n",
        "</fieldset>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThLThlHkIynQ"
      },
      "outputs": [],
      "source": [
        "#@title # üëá **Download model (can be run multiple times)**\n",
        "%cd /content\n",
        "import os\n",
        "link = \"\" #@param{type:\"string\"}\n",
        "from_direct_link = True #@param{type:\"boolean\"}\n",
        "from_gdrive = False #@param{type:\"boolean\"}\n",
        "from_torrent = False #@param{type:\"boolean\"}\n",
        "\n",
        "!mkdir -p /content/models\n",
        "%cd /content/models\n",
        "\n",
        "if from_gdrive:\n",
        "  !pip install -q -U gdown\n",
        "  !gdown -c --fuzzy \"{link}\"\n",
        "\n",
        "if from_torrent or from_direct_link:\n",
        "  !apt install -y -qq aria2\n",
        "\n",
        "if from_torrent:\n",
        "  !aria2c --summary-interval=10 --seed-ratio=0.1 --allow-overwrite=true \"{link}\"\n",
        "\n",
        "if from_direct_link:\n",
        "  !aria2c  --summary-interval=10 -c -x 10 -k 1M -s 10 \"{link}\"\n",
        "  # user_header = f\"\\\"Authorization: Bearer [HUGGING FACE TOKEN HERE]\\\"\"\n",
        "  # !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 \"{link}\"\n",
        "\n",
        "# Uncomment if necessary\n",
        "\n",
        "# Move any file inside a folder if there's any\n",
        "# !nohup mv **/*.zip /content/models\n",
        "# !nohup mv **/*.ckpt /content/models\n",
        "# !nohup mv **/*.pt /content/models\n",
        "\n",
        "# Unzip them if there is any (modify if needed)\n",
        "# !nohup unzip *.zip *.rar\n",
        "# !nohup tar *.tar *.tar\n",
        "# !rm -rf nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqv2nXeZtw3T"
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/diffusers\n",
        "# !mkdir -p /content/models\n",
        "link = \"https://huggingface.co/eimiss/EimisAnimeDiffusion_1.0v\" #@param{type:\"string\"}\n",
        "branch = \"main\" #@param{type:\"string\"}\n",
        "model_name = \"EimisAnimeDiffusion_1.0v-fp32\" #@param{type:\"string\"}\n",
        "# !sudo apt install git-lfs\n",
        "# !git lfs clone {link} -b {branch} /content/diffusers\n",
        "# !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_diffusers_to_original_stable_diffusion.py -O /content/convert_diffusers_to_original_stable_diffusion.py\n",
        "# !pip install \"git+https://github.com/huggingface/diffusers@main#egg=diffusers[torch]\"\n",
        "!python3 /content/convert_diffusers_to_original_stable_diffusion.py --model_path \"/content/diffusers\" --checkpoint_path \"/content/models/{model_name}.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDz0tKuKyR3u"
      },
      "outputs": [],
      "source": [
        "#@title # üëá **Convert to safetensor?** (in progress)\n",
        "%cd /content/models\n",
        "import os\n",
        "!pip install -q torch safetensors\n",
        "import torch\n",
        "from safetensors.torch import save_file\n",
        "def get_file_list(path):\n",
        "  res = []\n",
        "  for (dir_path, dir_names, file_names) in os.walk(path):\n",
        "      res.extend(file_names)\n",
        "  return res\n",
        "#@markdown If NAI based, use pop dict. \n",
        "pop_dict = False #@param {\"type\":\"boolean\"}\n",
        "delete_original_ckpt = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "for the_model in get_file_list(\"/content/models\"):\n",
        "  if os.path.splitext(os.path.basename(the_model))[1] == \".ckpt\":\n",
        "    weights = torch.load(the_model)[\"state_dict\"]\n",
        "    if pop_dict:\n",
        "      weights.pop(\"state_dict\")\n",
        "    print(\"Converting\",the_model,\", please wait...\")\n",
        "    save_file(weights, os.path.splitext(os.path.basename(the_model))[0]+\".safetensors\")\n",
        "    print(\"Success.\")\n",
        "    if delete_original_ckpt:\n",
        "      if os.path.exists(os.path.join(\"/content/models\",the_model)):\n",
        "        !rm -f /content/models/{the_model}\n",
        "\n",
        "    weights = \"\" # Clear ram\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7cmuFsM2p3n"
      },
      "outputs": [],
      "source": [
        "#@title # üëá **Convert from diffusers**\n",
        "# !rm -rf /content/diffusers\n",
        "!mkdir -p /content/models\n",
        "link = \"https://huggingface.co/eimiss/EimisAnimeDiffusion_1.0v\" #@param{type:\"string\"}\n",
        "branch = \"main\" #@param{type:\"string\"}\n",
        "model_name = \"EimisAnimeDiffusion_1.0v-fp32\" #@param{type:\"string\"}\n",
        "!sudo apt install git-lfs\n",
        "!git clone {link} -b {branch} /content/diffusers\n",
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_diffusers_to_original_stable_diffusion.py -O /content/convert_diffusers_to_original_stable_diffusion.py\n",
        "!pip install \"git+https://github.com/huggingface/diffusers@main#egg=diffusers[torch]\"\n",
        "!python3 /content/convert_diffusers_to_original_stable_diffusion.py --model_path \"/content/diffusers\" --checkpoint_path \"/content/models/{model_name}.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLAcycOlDTYH"
      },
      "outputs": [],
      "source": [
        "#@title # üëá **Upload them to Google Drive**\n",
        "!rm -f *.zip*\n",
        "from google.colab import drive\n",
        "import os\n",
        "if not os.path.exists('/content/gdrive'):\n",
        "  drive.mount('/content/gdrive')\n",
        "%cd /content/models\n",
        "output_path = \"ai_models/\" #@param {type:\"string\"}\n",
        "!rsync -a -f\"- */\" -f\"+ *\" --progress . \"/content/gdrive/MyDrive/\"{output_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNtETg_pEDhb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install -q huggingface_hub\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "models_path= \"/content/models\"\n",
        "upload_path= '/content/upload_models'\n",
        "\n",
        "#@title # **üëá Upload them to HuggingFace üöÄü§ó**\n",
        "#@markdown ## **How to use this?**<br>\n",
        "#@markdown 1. Grab your huggingface **write token** from [here](https://huggingface.co/settings/tokens)\n",
        "#@markdown 2. Paste the token, then write your repo name\n",
        "#@markdown 3. Run the cell\n",
        "#@markdown 4. Select model you want to upload (use `ctrl/shift` for multiple selection)\n",
        "#@markdown 5. Click on upload button\n",
        "\n",
        "api = HfApi()\n",
        "write_token = \"\"  #@param{type:\"string\"}\n",
        "if not os.path.exists('/root/.huggingface/token'):\n",
        "  !mkdir /root/.huggingface/\n",
        "  !touch /root/.huggingface/token\n",
        "f = open(\"/root/.huggingface/token\", \"w+\")\n",
        "f.write(write_token)\n",
        "f.close()\n",
        "\n",
        "user = api.whoami(write_token)\n",
        "repo = \"EimisAnimeDiffusion_1.0v\" #@param{type:\"string\"}\n",
        "username_repo = user['name']+\"/\"+repo.strip()\n",
        "validate_repo_id(username_repo)\n",
        "\n",
        "try:\n",
        "  api.create_repo(repo_id=username_repo)\n",
        "  print(\"Repo didn't exists, creating repo\")\n",
        "  print(\"Repo\",username_repo,\"created!\")\n",
        "except HfHubHTTPError as e:\n",
        "  print(\"Repo exists, skipping create repo\")\n",
        "  \n",
        "#@markdown ####<br> **‚ö†Ô∏è Rerun this cell if your colab crashed. Because sometimes it did ü´§**<br>\n",
        "#@markdown *If error, maybe you have \"read token\" instead of \"write token\"*\n",
        "def get_file_list(path):\n",
        "  res = []\n",
        "  for (dir_path, dir_names, file_names) in os.walk(path):\n",
        "      res.extend(file_names)\n",
        "  return res\n",
        "  \n",
        "selected = widgets.SelectMultiple(\n",
        "    options=get_file_list(models_path),\n",
        "    rows=10,\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "button = widgets.Button(\n",
        "    description='Upload',\n",
        "    disabled=False,\n",
        "    button_style='success',\n",
        "    tooltip='Upload to huggingface',\n",
        ")\n",
        "\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def upload_it(b):\n",
        "    with out:\n",
        "        if selected.value is not None:\n",
        "            clear_output()\n",
        "            !mkdir -p {upload_path}\n",
        "\n",
        "            #hard link each file\n",
        "            for selected_model in selected.value:\n",
        "              if not os.path.exists(os.path.join(upload_path,selected_model)):\n",
        "                os.link(os.path.join(models_path,selected_model),os.path.join(upload_path,selected_model)) #hardlinking to save colab's space\n",
        "            \n",
        "            #delete .ipynb_checkpoint\n",
        "            if os.path.exists(os.path.join(upload_path,\".ipynb_checkpoints\")):\n",
        "              !rm {upload_path}/.ipynb_checkpoints\n",
        "            print(\"Selected:\", \", \".join(selected.value))\n",
        "            print(\"Uploading to https://huggingface.co/\"+username_repo)\n",
        "            print(\"Please wait...\")\n",
        "\n",
        "            #upload\n",
        "            api.upload_folder(\n",
        "                folder_path=upload_path,\n",
        "                repo_id=username_repo,\n",
        "                commit_message=\"Upload with üöÄü§ó NoCrypt's ModelDL\"\n",
        "            )\n",
        "            \n",
        "            print(\"Done!\")\n",
        "            #delete hardlink\n",
        "            !rm -rf {upload_path}/*\n",
        "\n",
        "        else:\n",
        "            print(\"Nothing is selected\")\n",
        "            b.close()\n",
        "            selected.close()\n",
        "\n",
        "button.on_click(upload_it)\n",
        "print(\"Upload target: https://huggingface.co/\"+username_repo)\n",
        "print(\"üëá Select models you want to upload (use ctrl/shift for multiple selection) \")\n",
        "display(selected,button,out)\n",
        "\n",
        "\n",
        "# OLD CODE #\n",
        "# # üëá **Upload them to Hugging Face**\n",
        "# If error, maybe you have \"read token\" instead of \"write token\", or repo is already exists/not exists\n",
        "# <br> [GET WRITE TOKEN HERE](https://huggingface.co/settings/tokens)\n",
        "# !rm -f *.zip*\n",
        "# import os\n",
        "# !nohup pip install huggingface_hub > /dev/null\n",
        "# from huggingface_hub import HfApi\n",
        "# from huggingface_hub.utils import validate_repo_id\n",
        "# if os.path.exists(\"/content/models/.ipynb_checkpoints\"): \n",
        "#   !rm -rf /content/models/.ipynb_checkpoints\n",
        "# api = HfApi()\n",
        "# write_token = \"\"  #@param{type:\"string\"}\n",
        "# if not os.path.exists('/root/.huggingface/token'):\n",
        "#   !mkdir /root/.huggingface/\n",
        "#   !touch /root/.huggingface/token\n",
        "# f = open(\"/root/.huggingface/token\", \"w+\")\n",
        "# f.write(write_token)\n",
        "# f.close()\n",
        "\n",
        "# user = api.whoami(write_token)\n",
        "# repo = \"models\" #@param{type:\"string\"}\n",
        "# username_repo = user['name']+\"/\"+repo\n",
        "# validate_repo_id(username_repo)\n",
        "# is_new = \"new\" #@param[\"new\",\"existing\"]\n",
        "# if is_new == \"new\":\n",
        "#   api.create_repo(repo_id=username_repo)\n",
        "  \n",
        "# api.upload_folder(\n",
        "#     folder_path=\"/content/models\",\n",
        "#     repo_id=username_repo,\n",
        "# )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Gz4DA_qGGVzZ"
      },
      "outputs": [],
      "source": [
        "#@title # üëá **Remove all files (to download another model)**\n",
        "!rm -rf /content/models/*\n",
        "%cd /content/models"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
